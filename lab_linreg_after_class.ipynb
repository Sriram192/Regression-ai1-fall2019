{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "file_extension": ".py",
      "version": "3.6.8",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    },
    "anaconda-cloud": {},
    "nteract": {
      "version": "0.7.1"
    },
    "colab": {
      "name": "lab_linreg.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFMQ_R2dT3MI",
        "colab_type": "text"
      },
      "source": [
        "# Linear Regression Multiple Ways"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iC5G2sglT3MK",
        "colab_type": "text"
      },
      "source": [
        "## Making the data\n",
        "\n",
        "We'll first construct a synthetic data set..using a function from the `scikit-learn` library. Synthetic data is nice in the sense that we can constrain how the noise behaves, and thus isolate effects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3eXdH06T3ML",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "from sklearn.datasets import make_regression\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb7qSXBZT3MP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#code adapted from http://tillbergmann.com/blog/python-gradient-descent.html\n",
        "X, y, coef = make_regression(n_samples = 100, \n",
        "                       n_features=1, \n",
        "                       noise=20,\n",
        "                       random_state=2017,\n",
        "                       coef=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2m2EoH8UrOM_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a991089f-2cf3-46f7-96c8-174eb0f0bda4"
      },
      "source": [
        "X.shape\n",
        "y.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgKr3VJrrVZJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "adf15b98-b484-45e4-d8d2-f277565073d7"
      },
      "source": [
        "X\n",
        "y"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  11.53485189,  -66.78103659,   11.54184614,  -45.46060758,\n",
              "       -130.57522775,  -61.80354621,  -78.82405201,   -5.52030807,\n",
              "        -30.21885715,  165.55255054, -112.64693342,  106.90160571,\n",
              "        -58.10971419,    0.93779626,  -43.61435122,   26.95725272,\n",
              "        -42.66951584,  -57.13556708,  -95.79615005,  118.35209797,\n",
              "        -51.4373238 ,   84.19876031,  131.21777646,  -46.29521229,\n",
              "         21.0677083 ,  -94.24874166,  -40.44179061,  -88.60315002,\n",
              "         55.92737987,   -3.31000877,  -74.78446006,   20.5147989 ,\n",
              "        -62.67644286,   56.03461688, -157.7787645 ,  143.08307335,\n",
              "         15.3388511 ,   -9.59788063,   81.74740666,   71.32138227,\n",
              "         53.87402664,   -0.68947083, -141.90224262,  114.66818014,\n",
              "         23.3021041 ,   21.99009826,  -35.28545232, -129.8408221 ,\n",
              "        -94.74229488,  -75.84916088,   83.65977299,  112.44087428,\n",
              "        -55.5829791 ,  101.61972743,  -19.92492782,   29.31837579,\n",
              "        -32.59780898,  -68.49724243,  -27.785417  ,    2.34156788,\n",
              "         91.85243983,  -18.65189923,  -62.65682224, -106.91132157,\n",
              "         94.67652243,   51.95286644,  -50.99505229,   18.26148669,\n",
              "         51.05332207,  -56.34956543,   82.80577269,   18.01858792,\n",
              "         15.83091218,  -19.81500319,   82.39321467, -140.85104541,\n",
              "        -73.30560486,  -56.37186313,  -10.36158814,  -48.98645178,\n",
              "        -46.33524716,   67.6030705 ,  -53.78278273,   72.4408164 ,\n",
              "         83.26318   ,  -15.82696757,  -27.61063917, -196.54485984,\n",
              "         79.23147597,  -33.6596636 ,  -64.85173268,  -28.3827812 ,\n",
              "        -91.9824817 ,   56.10393455,  -21.18642162,  -88.07527261,\n",
              "         66.14927345,  215.9303478 ,   63.50572218,   -4.91329396])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AViIT7PGT3MS",
        "colab_type": "text"
      },
      "source": [
        "Notice that the X is in the canonical array-of-arrays format.\n",
        "**Try and print its shape**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7MiOT35T3MV",
        "colab_type": "text"
      },
      "source": [
        "We are fitting a model with an intercept. Lets see what it is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XplQfIMAT3MW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "314edcb7-1f0a-4a06-9a6d-513c7cc24374"
      },
      "source": [
        "coef"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(80.88336208)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7v_WLXreT3MZ",
        "colab_type": "text"
      },
      "source": [
        "We can plot the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7O20TP9DT3Ma",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "b3330a5c-9921-4ba3-bbb6-17867df79172"
      },
      "source": [
        "plt.plot(X,y, 'o');"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD8CAYAAAB6paOMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAqjkAAABVHIACAiiMQAEDF/T/ulJ+kwfwX+wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bo6Xl8ECT3Mc",
        "colab_type": "text"
      },
      "source": [
        "For the purposes of drawing the regression line, lets create a uniform grid of points, and then reshape it into the canonical format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBBA1AmjT3Md",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xgrid = np.linspace(-2.5,2.5,1000)\n",
        "Xgrid = xgrid.reshape(-1,1)\n",
        "#reshape just converts the size of the array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlRUi8dfsI_M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c7006525-2ce1-4cbc-d16d-53a022a880d8"
      },
      "source": [
        "Xgrid.shape,xgrid.shape\n",
        "#xgrid is avector and Xgrid is a matrix"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1000, 1), (1000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2WfAVcXT3Mf",
        "colab_type": "text"
      },
      "source": [
        "## Fit using sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oM6B22KsT3Mg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LinearRegression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11qPDDTrT3Mj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = LinearRegression()\n",
        "lr.fit(X,y)\n",
        "ypgrid = lr.predict(Xgrid)\n",
        "lr.coef_, lr.intercept_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLRAROJ0T3Mm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(Xgrid, ypgrid)\n",
        "plt.plot(X, y, '.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeisXZSzT3Mp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import r2_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsFnqUfJT3Ms",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "r2_score(y, lr.predict(X))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abVrmy00T3Mv",
        "colab_type": "text"
      },
      "source": [
        "## The impact of sample size\n",
        "\n",
        "We'll sample 20 points from the data set. We do this by sampling 20 indices, index into X and y, and then fit on the sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akmwMzaqT3Mv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_indices = np.random.choice(range(100), size=20)\n",
        "sample_indices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Iprep-eT3My",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xsample = X[sample_indices]\n",
        "ysample = y[sample_indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvBwnfcvT3M0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_s = LinearRegression().fit(Xsample, ysample)\n",
        "r2_score(ysample, lr_s.predict(Xsample)), lr_s.score(Xsample, ysample)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHF8qm9pT3M3",
        "colab_type": "text"
      },
      "source": [
        "Lets check the sensitivity of our prediction to our sample. We'll do this 1000 times"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97nKpsxmT3M4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scores = []\n",
        "for i in range(1000):\n",
        "    sample_indices = np.random.choice(range(100), size=20)\n",
        "    Xsample = X[sample_indices]\n",
        "    ysample = y[sample_indices]\n",
        "    scores.append(LinearRegression().fit(Xsample, ysample).score(Xsample, ysample))\n",
        "plt.hist(scores,  bins=np.linspace(0.7, 1, 30))\n",
        "plt.xlim(0.7,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwfUNg-ZT3M6",
        "colab_type": "text"
      },
      "source": [
        "Redo this with a higher amount of noise (about 400). For this you will need to create a new dataset. Plot the data. Plot the histogram of the R^2 as well as that of the coefficients.Try a smaller dataset as well. What conclusions can you draw?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-syY4_kHT3M7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# your code here\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ULPfXZ8T3M9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# your code here\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdN3vcpAT3NA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# your code here\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3VqhvdtT3NE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# your code here\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7ONoRVNT3NI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# your code here\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfOAyLvPT3NK",
        "colab_type": "text"
      },
      "source": [
        "## Testing and training\n",
        "\n",
        "A grid like the one we created might contain some of the points we fit this model on. This is called **Data Contamination** and is a big no-no. If we want an independent estimate of the error, we should hold out some points in a test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMfw3LjOT3NL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXHtlzHfT3NP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=2017)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdNHUKaIT3NS",
        "colab_type": "text"
      },
      "source": [
        "Now lets fit the model on the training set and evaluate it both on the training set and the test set. We print the R^2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMh-cauHT3NT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr2 = LinearRegression().fit(Xtrain, ytrain)\n",
        "r2_test = r2_score(ytest, lr.predict(Xtest))\n",
        "r2_train = r2_score(ytrain, lr.predict(Xtrain))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-Yl_BuDT3NV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"Train R2 is {}, while test R^2 is {}\".format(r2_train, r2_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMTtcbKkT3NX",
        "colab_type": "text"
      },
      "source": [
        "## Using Keras to fit the model\n",
        "\n",
        "We'll use plain and simple gradient descent (why?) and Keras's Sequential API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETADGzQiT3NY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "lr3 = Sequential()\n",
        "lr3.add(Dense(1, input_shape=(1,)))\n",
        "lr3.compile(optimizer='sgd', loss='mean_squared_error',  metrics=['mae','accuracy'])\n",
        "lr3.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OH3EpON5T3Nc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = lr3.fit(Xtrain, ytrain, epochs=400, batch_size=80)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xppHUeKHT3Ne",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history['loss'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFih_PeAT3Nh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr3.get_weights()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQbhJPawT3Nl",
        "colab_type": "text"
      },
      "source": [
        "### Using the Keras Functional API\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTE9nEaBT3Nl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "\n",
        "inputs_placeholder = Input(shape=(1,))\n",
        "outputs_placeholder = Dense(1, activation='linear')(inputs_placeholder)\n",
        "\n",
        "m = Model(inputs=inputs_placeholder, outputs=outputs_placeholder)\n",
        "m.compile(optimizer='sgd', loss='mean_squared_error',  metrics=['mae','accuracy'])\n",
        "m.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhiCnip1T3Nq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history2 = m.fit(Xtrain, ytrain, epochs=250, batch_size=80)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMObHaufT3Nt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m.get_weights()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}